{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cc8e957-d533-470d-93b3-c63db50aa634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c4eb517-a005-45c4-a8cd-a462b2e04a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 40 files\n"
     ]
    }
   ],
   "source": [
    "path = \"../results/\"\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "print(\"found {} files\".format(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ff16e1a-c2cb-429f-8b0c-3cd510c2f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupers = [\n",
    "    \"Cora_implicit_adams_stepsize_0.5\",\n",
    "    \"Cora_implicit_adams_stepsize_0.25\",\n",
    "    \"Cora_implicit_adams_stepsize_0.1\",\n",
    "    \"Cora_implicit_adams_stepsize_0.01\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee56d2c-416a-43c5-bbe4-6e36a094a965",
   "metadata": {},
   "source": [
    "## dictionary structure\n",
    "\n",
    "results['time'].append(time.time() - start_time)\\\n",
    "results['loss'].append(loss)\\\n",
    "results['forward_nfe'].append(model.fm.sum)\\\n",
    "results['backward_nfe'].append(model.bm.sum)\\\n",
    "results['train_acc'].append(train_acc)\\\n",
    "results['test_acc'].append(test_acc)\\\n",
    "results['val_acc'].append(val_acc)\\\n",
    "results['best_epoch'] = best_epoch\\\n",
    "results['best_train_acc'] = best_train_acc\\\n",
    "results['best_val_acc'] = best_val_acc\\\n",
    "results['best_test_acc'] = best_test_acc\\\n",
    "results['all_epochs_time'] = time.time() - overall_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab461d4e-faf7-4aee-867d-6241142d984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanVar2d(ll):\n",
    "    a = np.array(ll)\n",
    "    return {\n",
    "        'mean': np.mean(a,axis=0),\n",
    "        'var': np.var(a,axis=0),\n",
    "        'std': np.std(a,axis=0)\n",
    "    }\n",
    "\n",
    "def getMeanVar2dCollapse(ll):\n",
    "    a = np.array(ll)\n",
    "    return {\n",
    "        'mean': np.mean(a),\n",
    "        'var': np.var(a),\n",
    "        'std': np.std(a)\n",
    "    }\n",
    "\n",
    "def getMeanVar(l):\n",
    "    a = np.array(l)\n",
    "    return {\n",
    "        'mean': np.mean(a),\n",
    "        'var': np.var(a),\n",
    "        'std': np.std(a)\n",
    "    }\n",
    "\n",
    "def handle2d(resd, key, dicts):\n",
    "    d = getMeanVar2d([dic[key] for dic in dicts])\n",
    "    resd[key + '_mean'] = d['mean']\n",
    "    resd[key + '_var'] = d['var']\n",
    "    resd[key + '_std'] = d['std']\n",
    "    \n",
    "def handle2dCollapse(resd, key, dicts):\n",
    "    d = getMeanVar2dCollapse([dic[key] for dic in dicts])\n",
    "    resd[key + '_mean'] = d['mean']\n",
    "    resd[key + '_var'] = d['var']\n",
    "    resd[key + '_std'] = d['std']\n",
    "\n",
    "def handle1d(resd, key, dicts):\n",
    "    d = getMeanVar([dic[key] for dic in dicts])\n",
    "    resd[key + '_mean'] = d['mean']\n",
    "    resd[key + '_var'] = d['var']\n",
    "    resd[key + '_std'] = d['std']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6fffc72-f32f-41a6-ab6b-961dd70107de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all dicts have the same arguments. they are just different runs\n",
    "\n",
    "def handleDict(gstr, dicts):\n",
    "    resd = {}\n",
    "    gstrsplits = gstr.split(\"_\")\n",
    "    if gstr.startswith(\"Cora\"):\n",
    "        resd['name'] = gstrsplits[0]\n",
    "        resd['method'] = gstrsplits[1] + \"_\" + gstrsplits[2]\n",
    "        resd['stepsize'] = gstrsplits[4]\n",
    "    \n",
    "    handle2dCollapse(resd, 'time', dicts)\n",
    "    handle2d(resd, 'loss', dicts)\n",
    "    handle2d(resd, 'train_acc', dicts)\n",
    "    handle2d(resd, 'test_acc', dicts)\n",
    "    handle2d(resd, 'val_acc', dicts)\n",
    "    handle1d(resd, 'best_train_acc', dicts)    \n",
    "    handle1d(resd, 'best_val_acc', dicts)\n",
    "    handle1d(resd, 'best_test_acc', dicts)\n",
    "    handle1d(resd, 'all_epochs_time', dicts)\n",
    "    \n",
    "    pickle.dump(resd, open(\"../mlggm/results/{}_overall.pickle\".format(gstr), \"wb\" ))\n",
    "    #print(resd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98bb8b66-0c10-4b78-adbf-16233a37a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found for Cora_implicit_adams_stepsize_0.5 10 files\n",
      "found for Cora_implicit_adams_stepsize_0.25 10 files\n",
      "found for Cora_implicit_adams_stepsize_0.1 10 files\n",
      "found for Cora_implicit_adams_stepsize_0.01 10 files\n"
     ]
    }
   ],
   "source": [
    "for gstr in groupers:\n",
    "    runfiles = [f for f in files if f.startswith(gstr)]\n",
    "    runobj = []\n",
    "    for f in runfiles:\n",
    "        with (open(join(path,f), \"rb\")) as openfile:\n",
    "            runobj.append(pickle.load(openfile))\n",
    "    print(\"found for {} {} files\".format(gstr, len(runfiles)))\n",
    "    handleDict(gstr, runobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c494bf-0e53-4654-8662-be0b88ee056f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
