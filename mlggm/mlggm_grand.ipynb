{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import torch_sparse\n",
    "from torchdiffeq import odeint\n",
    "# from torchdiffeq import odeint_adjoint as odeint # Might be more stable according to docs of torchdiffeq\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from pathlib import Path\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "# Set torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Number of validation nodes: 500\n",
      "Number of test nodes: 1000\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = Path('data')\n",
    "dataset_dir = dataset_dir.absolute()\n",
    "if not dataset_dir.exists():\n",
    "    dataset_dir.mkdir(parents=True)\n",
    "\n",
    "dataset = Planetoid(dataset_dir, 'Cora')\n",
    "\n",
    "# Some info\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "data = dataset.data\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Number of validation nodes: {data.val_mask.sum()}')\n",
    "print(f'Number of test nodes: {data.test_mask.sum()}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "# # Plot the graph\n",
    "# G = nx.Graph()\n",
    "#\n",
    "# G.add_nodes_from(list(range(data.num_nodes)))\n",
    "# G.add_edges_from([tuple(x) for x in data.edge_index.T.tolist()])\n",
    "# nx.draw(G)\n",
    "# plt.gca().set_facecolor('white')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "# Train the given model on the given graph for num_epochs\n",
    "def train(model, optimizer, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x = data.x\n",
    "    y = data.y.squeeze()\n",
    "\n",
    "    # Set up the loss and the optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    out = model(x)\n",
    "\n",
    "    loss = loss_fn(out[data.train_mask], y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "class ODELayer(MessagePassing):\n",
    "    def __init__(self, in_features, out_features, device, opt):\n",
    "        super(ODELayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.opt = opt\n",
    "        self.device = device\n",
    "        self.w = nn.Parameter(torch.eye(opt['hidden_dim']))\n",
    "        self.d = nn.Parameter(torch.zeros(opt['hidden_dim']) + 1)\n",
    "        self.alpha_train = nn.Parameter(torch.tensor(0.0))\n",
    "        self.beta_train = nn.Parameter(torch.tensor(0.0))\n",
    "        self.x0 = None\n",
    "        self.nfe = 0\n",
    "        self.alpha_sc = nn.Parameter(torch.ones(1))\n",
    "        self.beta_sc = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, t, x):  # the t param is needed by the ODE solver.\n",
    "        ax = torch_sparse.spmm(self.edge_index, self.edge_weight, x.shape[0], x.shape[0], x)\n",
    "        alpha = torch.sigmoid(self.alpha_train)\n",
    "        f = alpha * (ax - x) # What is happening here?\n",
    "        f = f + self.beta_train * self.x0\n",
    "        return f"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "from torch_scatter import scatter_add\n",
    "def get_rw_adj(edge_index, edge_weight=None, norm_dim=1, fill_value=0., num_nodes=None, dtype=None):\n",
    "  num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "  if edge_weight is None:\n",
    "    edge_weight = torch.ones((edge_index.size(1),), dtype=dtype,\n",
    "                             device=edge_index.device)\n",
    "\n",
    "  if not fill_value == 0:\n",
    "    edge_index, tmp_edge_weight = add_remaining_self_loops(\n",
    "      edge_index, edge_weight, fill_value, num_nodes)\n",
    "    assert tmp_edge_weight is not None\n",
    "    edge_weight = tmp_edge_weight\n",
    "\n",
    "  row, col = edge_index[0], edge_index[1]\n",
    "  indices = row if norm_dim == 0 else col\n",
    "  deg = scatter_add(edge_weight, indices, dim=0, dim_size=num_nodes)\n",
    "  deg_inv_sqrt = deg.pow_(-1)\n",
    "  edge_weight = deg_inv_sqrt[indices] * edge_weight if norm_dim == 0 else edge_weight * deg_inv_sqrt[indices]\n",
    "  return edge_index, edge_weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "class ConstantODEblock(nn.Module):\n",
    "  def __init__(self, odefunc, opt, data, device, t):\n",
    "    super(ConstantODEblock, self).__init__()\n",
    "\n",
    "    self.opt = opt\n",
    "    self.t = t\n",
    "    self.odefunc = odefunc(opt['hidden_dim'], opt['hidden_dim'], device, opt)\n",
    "    # edge_index = data.edge_index # Note these are normalized in the original code (why?)\n",
    "    # edge_weight = torch.ones((edge_index.size(1),), dtype=data.x.dtype, device=device) # Note these are normalized in the original code (why?)\n",
    "\n",
    "    edge_index, edge_weight = get_rw_adj(data.edge_index, edge_weight=data.edge_attr, norm_dim=1,\n",
    "                                                           fill_value=1,\n",
    "                                                           num_nodes=data.num_nodes,\n",
    "                                                           dtype=data.x.dtype)\n",
    "\n",
    "    self.odefunc.edge_index = edge_index.to(device)\n",
    "    self.odefunc.edge_weight = edge_weight.to(device)\n",
    "\n",
    "    self.train_integrator = odeint\n",
    "    self.test_integrator = odeint\n",
    "    self.atol = 1e-7 # Not necessary for euler\n",
    "    self.rtol = 1e-9 # Not necessary for euler\n",
    "\n",
    "  def forward(self, x):\n",
    "    t = self.t.type_as(x)\n",
    "\n",
    "    integrator = self.train_integrator if self.training else self.test_integrator\n",
    "\n",
    "    func = self.odefunc\n",
    "    state = x\n",
    "    state_dt = integrator(\n",
    "        func, state, t,\n",
    "        method='dopri5',\n",
    "        options=dict(step_size=1, max_iters=100),\n",
    "        atol=self.atol,\n",
    "        rtol=self.rtol)\n",
    "\n",
    "    z = state_dt[1]\n",
    "    return z\n",
    "\n",
    "  def set_x0(self, x0):\n",
    "    self.odefunc.x0 = x0.clone().detach()\n",
    "\n",
    "  def set_time(self, time):\n",
    "    self.t = torch.tensor([0, time]).to(self.device)\n",
    "\n",
    "  def __repr__(self):\n",
    "    return self.__class__.__name__ + '( Time Interval ' + str(self.t[0].item()) + ' -> ' + str(self.t[1].item()) \\\n",
    "           + \")\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "class GNN(MessagePassing):\n",
    "  def __init__(self, opt, dataset, device=torch.device('cpu')):\n",
    "    super(GNN, self).__init__()\n",
    "    self.opt = opt\n",
    "    self.T = opt['time']\n",
    "    time_tensor = torch.tensor([0, self.T]).to(device)\n",
    "    self.num_classes = dataset.num_classes\n",
    "    self.num_features = dataset.data.num_features\n",
    "    self.num_nodes = dataset.data.num_nodes\n",
    "    self.device = device\n",
    "\n",
    "    self.f = ODELayer\n",
    "    self.odeblock = ConstantODEblock(self.f, opt, dataset.data, device, t=time_tensor).to(device)\n",
    "\n",
    "    self.m1 = nn.Linear(self.num_features, opt['hidden_dim'])\n",
    "    self.hidden_dim = opt['hidden_dim']\n",
    "    self.m2 = nn.Linear(opt['hidden_dim'], dataset.num_classes)\n",
    "\n",
    "  def getNFE(self):\n",
    "    return self.odeblock.odefunc.nfe\n",
    "\n",
    "  def resetNFE(self):\n",
    "    self.odeblock.odefunc.nfe = 0\n",
    "\n",
    "  def reset(self):\n",
    "    self.m1.reset_parameters()\n",
    "    self.m2.reset_parameters()\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Encode each node based on its feature.\n",
    "    # x = F.dropout(x, self.opt['input_dropout'], training=self.training)\n",
    "    x = self.m1(x)\n",
    "\n",
    "    self.odeblock.set_x0(x)\n",
    "    z = self.odeblock(x)\n",
    "\n",
    "    # Activation.\n",
    "    z = F.relu(z)\n",
    "\n",
    "    # We can make it deep\n",
    "    # for i in range(5):\n",
    "    #     self.odeblock.set_x0(z)\n",
    "    #     z = self.odeblock(z)\n",
    "    #     z = F.relu(z)\n",
    "\n",
    "    # Dropout.\n",
    "    # z = F.dropout(z, self.opt['dropout'], training=self.training)\n",
    "\n",
    "    # Decode each node embedding to get node label.\n",
    "    z = self.m2(z)\n",
    "    return z\n",
    "\n",
    "  def __repr__(self):\n",
    "    return self.__class__.__name__\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "def print_model_params(model):\n",
    "  print(model)\n",
    "  for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "      print(name)\n",
    "      print(param.data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "# def set_train_val_test_split(\n",
    "#         seed: int,\n",
    "#         data: Data,\n",
    "#         num_development: int = 1500,\n",
    "#         num_per_class: int = 20) -> Data:\n",
    "#   rnd_state = np.random.RandomState(seed)\n",
    "#   num_nodes = data.y.shape[0]\n",
    "#   development_idx = rnd_state.choice(num_nodes, num_development, replace=False)\n",
    "#   test_idx = [i for i in np.arange(num_nodes) if i not in development_idx]\n",
    "#\n",
    "#   train_idx = []\n",
    "#   rnd_state = np.random.RandomState(seed)\n",
    "#   for c in range(data.y.max() + 1):\n",
    "#     class_idx = development_idx[np.where(data.y[development_idx].cpu() == c)[0]]\n",
    "#     train_idx.extend(rnd_state.choice(class_idx, num_per_class, replace=False))\n",
    "#\n",
    "#   val_idx = [i for i in development_idx if i not in train_idx]\n",
    "#\n",
    "#   def get_mask(idx):\n",
    "#     mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "#     mask[idx] = 1\n",
    "#     return mask\n",
    "#\n",
    "#   data.train_mask = get_mask(train_idx)\n",
    "#   data.val_mask = get_mask(val_idx)\n",
    "#   data.test_mask = get_mask(test_idx)\n",
    "#\n",
    "#   return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data, opt=None):  # opt required for runtime polymorphism\n",
    "  model.eval()\n",
    "  logits, accs = model(data.x), []\n",
    "  for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "    pred = logits[mask].max(1)[1]\n",
    "    acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "    accs.append(acc)\n",
    "  return accs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/anaconda3/envs/grand2/lib/python3.7/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: Dopri5Solver: Unexpected arguments {'step_size': 1, 'max_iters': 100}\n",
      "  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Runtime 1.281130, Loss 1.949133, Train: 0.5000, Val: 0.3480, Test: 0.3140, Best time: 18.2940\n",
      "best val accuracy 0.348000 with test accuracy 0.314000 at epoch 1 and best time 18.294000\n",
      "Epoch: 002, Runtime 1.368799, Loss 1.876029, Train: 0.8357, Val: 0.6780, Test: 0.6790, Best time: 18.2940\n",
      "best val accuracy 0.678000 with test accuracy 0.679000 at epoch 2 and best time 18.294000\n",
      "Epoch: 003, Runtime 1.048199, Loss 1.706633, Train: 0.8857, Val: 0.7140, Test: 0.7190, Best time: 18.2940\n",
      "best val accuracy 0.714000 with test accuracy 0.719000 at epoch 3 and best time 18.294000\n",
      "Epoch: 004, Runtime 0.853470, Loss 1.434530, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 005, Runtime 0.882504, Loss 1.118515, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 006, Runtime 0.906150, Loss 0.873465, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 007, Runtime 0.908864, Loss 0.714862, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 008, Runtime 0.906684, Loss 0.589132, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 009, Runtime 0.906309, Loss 0.532542, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 010, Runtime 0.891390, Loss 0.433212, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 011, Runtime 0.894843, Loss 0.433216, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 012, Runtime 0.889279, Loss 0.350942, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 013, Runtime 0.893994, Loss 0.388395, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 014, Runtime 1.089584, Loss 0.300120, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 015, Runtime 1.190292, Loss 0.358006, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 016, Runtime 0.906652, Loss 0.262152, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 017, Runtime 0.831504, Loss 0.346134, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 018, Runtime 0.830791, Loss 0.247560, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 019, Runtime 0.834096, Loss 0.338855, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 020, Runtime 1.069803, Loss 0.236867, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 021, Runtime 0.832606, Loss 0.313320, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 022, Runtime 0.833846, Loss 0.223891, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 023, Runtime 1.032441, Loss 0.311423, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 024, Runtime 0.899023, Loss 0.216756, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 025, Runtime 1.020060, Loss 0.308036, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 026, Runtime 0.870501, Loss 0.203378, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 027, Runtime 0.958287, Loss 0.294927, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 028, Runtime 0.900558, Loss 0.195923, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 029, Runtime 1.096662, Loss 0.289724, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 030, Runtime 1.007250, Loss 0.186970, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 031, Runtime 0.826570, Loss 0.282241, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 032, Runtime 0.993332, Loss 0.180285, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 033, Runtime 1.494806, Loss 0.273549, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 034, Runtime 1.245481, Loss 0.169964, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 035, Runtime 0.996747, Loss 0.264903, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 036, Runtime 0.838640, Loss 0.163016, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 037, Runtime 0.806867, Loss 0.266485, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 038, Runtime 0.808296, Loss 0.170516, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 039, Runtime 0.805854, Loss 0.259407, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 040, Runtime 0.807460, Loss 0.155954, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 041, Runtime 0.806566, Loss 0.249720, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 042, Runtime 0.806648, Loss 0.149033, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 043, Runtime 0.795771, Loss 0.246838, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 044, Runtime 0.783984, Loss 0.141988, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 045, Runtime 0.796964, Loss 0.239768, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 046, Runtime 0.773872, Loss 0.139543, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 047, Runtime 0.774792, Loss 0.236050, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 048, Runtime 0.775766, Loss 0.133132, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 049, Runtime 0.774635, Loss 0.229944, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 050, Runtime 0.776195, Loss 0.127894, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 051, Runtime 0.773287, Loss 0.225876, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 052, Runtime 0.774657, Loss 0.123314, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 053, Runtime 0.774081, Loss 0.220923, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 054, Runtime 0.774232, Loss 0.119399, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 055, Runtime 0.773534, Loss 0.216012, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 056, Runtime 0.774643, Loss 0.115632, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 057, Runtime 0.762503, Loss 0.211912, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 058, Runtime 0.754407, Loss 0.112135, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 059, Runtime 0.766116, Loss 0.208987, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 060, Runtime 0.740029, Loss 0.109882, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 061, Runtime 0.741797, Loss 0.204697, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 062, Runtime 0.743273, Loss 0.106498, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 063, Runtime 0.744134, Loss 0.202834, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 064, Runtime 0.741230, Loss 0.103432, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 065, Runtime 0.743922, Loss 0.200093, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 066, Runtime 0.742495, Loss 0.101235, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 067, Runtime 0.742145, Loss 0.197198, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 068, Runtime 0.740380, Loss 0.098615, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 069, Runtime 0.740312, Loss 0.194829, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 070, Runtime 0.740843, Loss 0.096403, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 071, Runtime 0.741704, Loss 0.192752, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 072, Runtime 0.740646, Loss 0.094658, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 073, Runtime 0.728634, Loss 0.190627, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 074, Runtime 0.710244, Loss 0.092428, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 075, Runtime 0.710058, Loss 0.188763, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 076, Runtime 0.710509, Loss 0.090846, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 077, Runtime 0.710166, Loss 0.186933, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 078, Runtime 0.707845, Loss 0.088999, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 079, Runtime 0.709481, Loss 0.185841, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 080, Runtime 0.710059, Loss 0.087298, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 081, Runtime 0.709200, Loss 0.184492, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 082, Runtime 0.708863, Loss 0.085988, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 083, Runtime 0.708227, Loss 0.182802, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 084, Runtime 0.709228, Loss 0.084204, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 085, Runtime 0.708262, Loss 0.180976, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 086, Runtime 0.689488, Loss 0.082821, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 087, Runtime 0.699486, Loss 0.179654, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 088, Runtime 0.678414, Loss 0.082039, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 089, Runtime 0.678726, Loss 0.176801, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 090, Runtime 0.679562, Loss 0.080609, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 091, Runtime 0.678463, Loss 0.175572, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 092, Runtime 0.679428, Loss 0.079138, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 093, Runtime 0.677099, Loss 0.174254, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 094, Runtime 0.675536, Loss 0.077789, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 095, Runtime 0.680013, Loss 0.173129, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 096, Runtime 0.676854, Loss 0.076497, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 097, Runtime 0.676654, Loss 0.171673, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 098, Runtime 0.677191, Loss 0.075119, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n",
      "Epoch: 099, Runtime 0.669342, Loss 0.169842, Train: 0.9000, Val: 0.7840, Test: 0.7760, Best time: 18.2940\n",
      "best val accuracy 0.784000 with test accuracy 0.776000 at epoch 4 and best time 18.294000\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    'hidden_dim': 80,\n",
    "    'time': 18.294,\n",
    "    'epoch': 100,\n",
    "    'input_dropout': 0,\n",
    "    'droput': 0,\n",
    "}\n",
    "\n",
    "\n",
    "model = GNN(opt, dataset, device).to(device)\n",
    "# dataset.data = set_train_val_test_split(np.random.randint(0, 1000), dataset.data, 1500)\n",
    "data = dataset.data.to(device)\n",
    "parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "# print_model_params(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "best_time = best_epoch = train_acc = val_acc = test_acc = 0\n",
    "\n",
    "for epoch in range(1, opt['epoch']):\n",
    "    start_time = time.time()\n",
    "\n",
    "    loss = train(model, optimizer, data)\n",
    "    tmp_train_acc, tmp_val_acc, tmp_test_acc = test(model, data, opt)\n",
    "\n",
    "    best_time = opt['time']\n",
    "    if tmp_val_acc > val_acc:\n",
    "      best_epoch = epoch\n",
    "      train_acc = tmp_train_acc\n",
    "      val_acc = tmp_val_acc\n",
    "      test_acc = tmp_test_acc\n",
    "      best_time = opt['time']\n",
    "\n",
    "    log = 'Epoch: {:03d}, Runtime {:03f}, Loss {:03f}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Best time: {:.4f}'\n",
    "    print(log.format(epoch, time.time() - start_time, loss, train_acc, val_acc, test_acc, best_time))\n",
    "    print('best val accuracy {:03f} with test accuracy {:03f} at epoch {:d} and best time {:03f}'.format(val_acc, test_acc,\n",
    "                                                                                                     best_epoch,\n",
    "                                                                                                     best_time))\n",
    "# train_acc, val_acc, test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}